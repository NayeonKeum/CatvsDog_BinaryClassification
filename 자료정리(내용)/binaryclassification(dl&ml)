Cat vs Dog ; Binary Classification using keras
목차

1. Artificial Intelligence

2. 머신러닝과 딥러닝의 차이점
(1) 일반적인 차이점
(2) 식별 문제에서의 차이점

3. 딥러닝의 종류

4. 딥러닝의 핵심
4.1 인공 신경망(ANNs)
(1) 인공신경망 대 생물 신경망
(2) Feedforward 신경망
(3) 활성화 함수
(4) 인공 신경망 훈련하기

4.2 합성곱 신경망(Convolutional Neural Networks) (CNN 혹은 ConvNets)
(1) 합성곱 레이어
(2) 풀링 레이어
(3) 합성곱 신경망 아키텍쳐

5. Classification
(1) Classification
(2) Classfication + Localization
(3) Object Detection
(4) Instance Segmenatation
(5) Classification Architecture
(6) Feature Map

6. 케라스 소개

1. Artificial Intelligence

(1) AI : 인간의 지시에 완벽하게 수동적인 기계를(Old Machine) 자율적으로 판단하고 행동하는 능동적인 기계(Smart Machine)로 변화시키는 모든 관련 기술들의 집합
(2) 머신러닝 : 컴퓨터가 수행하는 통계적 학습으로 컴퓨터가 사람이 뽑은 data feature를 ᅟᅩᆼ해 표본 데이터 속에 존재하는 전체 모수로 일반화 가능한 패턴을 찾아 스스로 학습하는 과정
(3) 딥러닝 : 다수의 학습 데이터셋을 통해 주로 심층 신경망(neural network)를 이용하여 스스로 학습하며 고차원적인 판단이 가능


2. 머신러닝과 딥러닝의 차이점
(1) 일반적인 차이점

+딥러닝의 경우 * End to End
통째로 데이터를 넣으면 학습을 스스로하기 때문에, 어느 곳을 더 유심히 봐야할지 알아서 판단
전처리 과정 없이 Input data만 넣으면 알아서 학습하고 output이 나오는 모델
2) 전처리
머신러닝에서는 딥러닝과 다르게 항상 데이터의 feature를 뽑아서 input으로 넣어줘야 하는 특성이 있기 때문에 필수적. 예를 들어, '고양이의 발은 여기 있고, 귀는 여기 있으니 이곳을 유심히 봐' 라고 알려주는 역할 /힌트를 주는 것
End to End로 사진이나 데이터를 넣어 줄 수 있음. 반면에, 머신러닝의 경우 사람이 직접 feature를 찾아서 넣어줘야만 한다는 차이점
+포함관계이다. ML 과정 중 신경망이 two-layer 이상의 김층 네트워크를 가지는 것을 DL이라고 한다.

(2) 식별 문제에서의 차이점
  (a) 머신러닝 알고리즘을 통한 식별의 2단계:
 ㄱ) 훈련(Train) 단계: 이미지와 각각의 라벨로 구성된 데이터셋을 사용하여 머신러닝 알고리즘을 훈련시킵니다.
  - 특징점 추출: 이 단계는 도메인 지식(역자 주, 어떤 물체는 엣지가 많고 다른 물체는 둥그스름한게 많다라는 등의 지식)을 활용하여 머신러닝 알고리즘에서 사용할 특징점들을 찾아냅니다.
  - 모델 훈련(Model Training): 이 단계에서는 이미지의 특징점에서 만든 깨끗한 데이터 셋(역자 주, 가장 전형적이라 생각되는 어떤 대표 이미지 예를 들어 누구라도 개 또는 고양이임을 알 수 있는 사진 혹은 그림)을 활용하여 각각의 라벨을 붙여서 머신러닝 모델을 훈련합니다.

 
 ㄴ) 예측(Predict) 단계: 훈련된 모델을 사용하여 처음 보는 이미지에 적용할 라벨을 예측
  -예측 단계에서는 동일한 특징점 추출 과정을 적용하여 새로운 이미지를 처리하고 이 특징점을 훈련된 머신러닝 알고리즘에 넣어서(Pass) 라벨을 예측합니다.



(b) 전통적인 머신러닝 기법과 딥러닝 알고리즘의 가장 큰 차이점은 특징점을 찾는 과정입니다. 전통적인 머신러닝 알고리즘은 우리가 각각의 특징점들을 직접 만들어야만 합니다. 반대로 딥러닝 알고리즘에서는 알고리즘 스스로 그러한 특징점을 찾아갑니다. 특징점 추출은 어렵고 시간을 잡아먹으며 특히 도메인 지식이 많이 필요합니다. 딥러닝의 가장 큰 장점은 머신러닝에 비해 특징점을 찾는데 기울이는 노력이 적거나 거의 없게 된다는 점입니다.


3. 딥러닝의 종류
(1) 지도학습 vs 반지도학습 vs 비지도학습의 구분 : 트레이닝 데이터에 붙어있는 정답 값(label)이 존재하느냐, 일부만 존재하느냐, 존재하지 않느냐로 구분



(2) Classification vs Clustering 
  (a) Classification : 주어진 데이터를 주어진 라벨(클래스)에 의해 분류하는 법을 학습
  -label이 붙어있는 output 값으로 각각의 데이터를 분류하기 위해서, Supervised - Learning을 통해서 classifier로 분류하는 과정
  (b) Clustering : 주어진 데이터를 데이터의 특징에 의해 스스로 클래스로 분류
  -각각의 데이터들에 label이 붙어있지 않아도, 이들의 특성을 판단하여 알고리즘이 스스로 그들을 군집화 시키는 과정


(3) Classification & Regression
  (a) Classification : 주어진 데이터가 어떤 라벨(클래스)인지 예측하는 것으로 discrete한 output을 가짐
  -각각의 label에 대해서 분류를 하는 반면 이를 descrete한 class에 대해서 수행함
  (b) Regression : 주어진 데이터의 경향성을 파악하고 함수를 예측하는 것으로 시계열의 미래의 값을 예측가능하며 연속적인 output을 가짐
-Discrete한 class가 존재하는 것이 아니라, data 자체가 continuous한 class에 대해 수행함. 이를 통해, 잘 예측할 수 있는 function을 만드는 것이 Regression의 목표이기 때문에 어떤 시점의 값 즉, 미래의 값을 예측할 수 있음. 즉, 현재 가지고 있는 data 특성을 통해서 어떠한 function을 얻었을 때, 미래의 data 또한 예측이 가능함

(4) features & class의 수
  (a) class의 수 : 나누고자하는 label의 종류 개수에 따라 다른 접근법을 사용하며 Classifier을 선택하는 데 중요한 요소이다.
  - label이 두 종류일 경우 binary classification
  - 여러개의 class를 가지고 있다면 multi-class classification
  (b) Data feature의 특징
  -Linear classifier : 데이터가 선형으로 잘 분류할 수 있는 구조를 가지고 있다면, 'Linear classifier'로 충분히 분류가 가능하다. 데이터가 선으로 분류하려고 해도 분류가 되지 않는 경우에는, 다른 classifier 종류를 고민해야 함
  -Nonlinear classifier : 위와 같이 분류되지 않는 경우에 해당. 'B' 그래프의 비선형 data를 어떠한 function을 이용해서 'A'와 같이 Mapping 할 수 있다면 다른 차원에서 Linear classifier로 표현될 수 있음. 즉, Mapping 된 공간에서는 선형적(Linear)으로 표현 가능






4. 딥러닝의 핵심

 딥러닝은 여러 처리 레이어를 포함하는 인공 신경망(Artificial Neural Network)의 클래스를 의미합니다. ANN의 개념은 수십년간 존재해왔지만 2000년대 중반 Geoffrey Hinton이 뚫기 전까지 ANN 구조를 깊게 훈련하는(Training Deep)시도는 번번히 실패해왔습니다. 알고리즘적인 혁신 뿐만 아니라 GPU 성능의 급격한 발전, 그리고 엄청나게 큰 데이터들이 쌓이면서 딥러닝은 급격한 발전을 이룩합니다.

4.1 인공 신경망(ANNs)

인공 신경망(ANNs)은 새포생물학적인 신경망으로부터 착안한 머신 러닝의 조합입니다.

(1) 인공신경망 대 생물 신경망

잠시 고등학교 생물시간으로 돌아가 볼까요? 생물학적 신경은 인간의 뇌를 구성하는 가장 핵심적인 부분입니다. 하나의 신경은 1개의 새포, 수상돌기(Dentrites) 그리고 축색돌기(Axon)로 이루어져있습니다. 밑의 그림에서 참고 바랍니다. 
신경 세포가 처리한 정보는 전기신호를 통해 다른 신경에 전달됩니다. 각각의 신경은 수상돌기를 통해 신호를 입력받고 다시 축색돌기로 출력합니다. 축색돌기는 시냅스를 통해 연결된 다른 새포의 수상돌기로 뻩어나갑니다.

신경이 작동하는 가장 단순한 모델은 다음과 같습니다: 각각의 시냅스는 학습이 가능한 강도를 가지고 있고 그것의 강도를 조절하여 신경간의 영향을 제어합니다. 수상돌기는 그것의 총합이 목표 신경의 몸체에 전달할 신호를 가지고 있습니다. 만약 최종 합이 어떤 임계값을 넘는다면 신경은 활성화되고 축색돌기를 통해 자극을 전달합니다. [1]

인공 신경은 생물학적 신경으로부터 영감을 얻어 위에 서술한 모델을 컴퓨터화된 방식으로 구체화하였습니다. 하나의 인공 신경은 각각 특정한 정도(Weight)를 가진 유한한 숫자의 입력과 하나의 활성화 함수(전달함수라 불리기도 하는)로 구성되어 있습니다. 신경의 출력은 결국 이러한 입력의 총합이 이 활성화 함수를 거쳐서 나온 결과입니다. 인공 신경은 서로 연결되어 있어서 인공 신경망을 구성합니다.



(2) Feedforward 신경망

피드포워드 신경망은 인공 신경망의 가장 간단한 구조입니다.
이 네트워크에는 3가지 종류의 레이어가 있습니다: 입력 레이어(단), 은닉(Hidden) 단 그리고 출력단 입니다. 이 네트워크 안에서 데이터는 입력단으로부터 들어가서 은닉단을 거쳐 출력 노드로 나갑니다.

아래는 완전 연결된 2개의 은닉단을 포함하는 피드포워드 신경망을 나타내고 있습니다. "완전 연결"이라는 말은 각각의 노드들이 다음 노드들과 모두 연결되어 있음을 의미합니다.

은닉단의 갯수와 그것의 크기만이 유일한 독립(변경되는) 변수입니다. 이론적으로 은닉단이 크고 깊을수록 더욱 복잡한 패턴을 모델링할 수 있다고 알려져 있습니다.


(3) Activation Function(활성화 함수)

활성화 함수는 입력의 가중합(Weighted sum)을 인공 신경에 전달하는 역할을 합니다. 이러한 함수는 데이터의 복잡한 패턴을 수치화하기 위해 비선형 함수여야 합니다.  선형함수인 h(x)=cx를 활성화함수로 사용한 3층 네트워크를 떠올려 보세요. 이를 식으로 나타내면 y(x)=h(h(h(x)))가 됩니다. 이는 실은 y(x)=ax와 똑같은 식입니다. a=c3이라고만 하면 끝이죠. 즉, 은닉층이 없는 네트워크로 표현할 수 있습니다. 뉴럴네트워크에서 층을 쌓는 혜택을 얻고 싶다면 활성화함수로는 반드시 비선형 함수를 사용해야 합니다.
선형을 사용할 시 층을 깊게하는 의미가 없기 때문입니다.

가장 널리 사용되는 활성화 함수는 Sigmoid, Tanh 그리고 ReLU입니다. 그중에서 ReLU는 딥러닝 신경망에서 가장 많이 사용됩니다.
 
(설명은 정해지면 한 개만 추가)


(4) 인공 신경망 훈련하기

훈련 단계의 목표는 망의 가중치를 학습하는 것입니다. 우리는 인공 신경망을 훈련하기 위해 2개의 요소가 필요합니다:
 - 훈련 데이터(Training data): 이미지 식별에 있어서 훈련 데이터는 여러 이미지들과 각 이미지에 해당하는 라벨을 포함합니다.
 - 손실 함수(Loss function): 예측한 값의 부정확한 정도를 측정하는 함수


4.2 합성곱 신경망(Convolutional Neural Networks) (CNN 혹은 ConvNets)

 합성곱 신경망은 특수한 형태의 Feed-forward 망입니다. 이 모델은 시신경이 동작하는 방식을 모사하기 위해 만들어졌습니다. CNN은 영상 인식에 매우 잘 동작합니다. CNN은 신경망으로 하여금 특정한 영상의 특징을 수치화할 수 있도록 하는 합성곱 레이어와 풀링(Pooling)레이어를 가지고 있습니다. ConvNet은 학습 가능한 가중치 (weight)와 바이어스(bias)로 구성되어 있다. 각 뉴런은 입력을 받아 내적 연산( dot product )을 한 뒤 선택에 따라 비선형 (non-linear) 연산을 한다. 전체 네트워크는 일반 신경망과 마찬가지로 미분 가능한 하나의 스코어 함수 (score function)을 갖게 된다 (맨 앞쪽에서 로우 이미지 (raw image)를 읽고 맨 뒤쪽에서 각 클래스에 대한 점수를 구하게 됨). 또한 ConvNet은 마지막 레이어에 (SVM/Softmax와 같은) 손실 함수 (loss function)을 가지며, 우리가 일반 신경망을 학습시킬 때 사용하던 각종 기법들을 동일하게 적용할 수 있다.
ConvNet과 일반 신경망의 차이점은 무엇일까? ConvNet 아키텍쳐는 입력 데이터가 이미지라는 가정 덕분에 이미지 데이터가 갖는 특성들을 인코딩 할 수 있다. 이러한 아키텍쳐는 포워드 함수 (forward function)을 더욱 효과적으로 구현할 수 있고 네트워크를 학습시키는데 필요한 모수 (parameter)의 수를 크게 줄일 수 있게 해준다.


(1) 합성곱 레이어(ConvNet Layer) 

이 레이어는 필터의 엔트리와 입력 이미지를 dot product 한 계산을 통해 이미지를 구조적으로 잘라낼 수 있는 학습 가능한 여러개의 필터로 구성되어 있습니다. 필터는 입력 이미지의 최대 깊이만큼 확장되어야 합니다. 예를들어 크기가 32x32인 칼라 이미지에 크기가 5x5인 필터를 적용하고자 한다면 3개의 컬러 채널(적색, 녹색, 청색)을 커버하기 위해서 이 필터의 깊이는 반드시 3이 되어야 합니다.(5x5x3) 이러한 필터는 이미지에서 유사한 구조를 발견할 때 활성화 될 것입니다.



(2) 풀링 레이어

풀링이란 비선형 다운 샘플링(Down sampling)의 형태를 취합니다. 풀링 단의 목표는 이미지의 공간적 크기를 점진적으로 줄여서 신경망의 변수, 연산 량을 줄여서 오버 피팅을 제어할 수 있도록 하는 것입니다. 풀링을 구성하는 것에는 여러가지 함수가 있지만 맥스풀링(Max pooling)이 가장 널리 사용됩니다. 풀링은 보통 stride가 2인 2x2크기의 필터를 각 깊이에 적용하게 됩니다. 크기가 2x2이고 stride가 2인 풀링단은 입력 영상을 원래 크기의 1/4로 줄입니다.



(3) 합성곱 신경망 아키텍쳐

합성곱 신경망의 가장 기본적인 구조는 입력단(이미지)으로부터 시작하여 일련의 합성곱 레이어와 풀링 레이어로 이어지고 완전 연결된 레이어로 끝납니다. 합성곱 레이어는 보통 한개의 ReLU 활성함수 순서로 되어있습니다. 합성곱, 풀링 그리고 ReLU 레이어는 학습 가능한 특징점 추출기 역할을 하고 완전 연결된 레이어는 하나의 머신러닝 식별자 역할을 한다. 특히 신경망의 초기 단계는 이미지의 일반적인 패턴을 수치화 하고 후반에서는 이미지의 세부적인 디테일을 수치화합니다. 합성곱 레이어와 완전 연결된 레이어에서만 가중치(Weights)가 있음을 유의하세요. 이 가중치들은 훈련 단계에서 학습됩니다.
(4) 합성곱 신경망 아키텍쳐의 한 예.







5. Classification
(1)Classification이란?
어떤 물체가 있을 때, 이 물체가 우리가 알고자하는 Class 내부에 있는지 or 없는지
그리고 그 클래스 중, 어떤 Class에 해당하는지를 표현하는 것

(2)Classfication + Localization이란?
물체의 위치가 어디에 있는지를 판단하는 것

(3)Object Detection이란?
Classfication과 Localization 둘 다 수행
물체가 어디에 있고 어떤 물체가 있는지 그리고 한 물체뿐만 아니라 여러 물체가 있을 때, Multi object detection을 수행할 수 있음

(4)Instance Segmenatation이란?
물체들이 어떤 것인지, 어디에있는지도 판단하지만 어떤 픽셀에 존재를 하는지까지 segmentation 할 수 있는 알고리즘



(5) Classification Architecture
주로 CNN 구조를 사용한다고 가정
1) Feature extraction & 2) Learning & 3) Classfication 크게 세 가지 과정으로 구분되어 있음
이 중, 가장 마지막 부분, Classifing을 하는 softmax로 되어 있는 곳이 가장 중요
왜냐하면, 우리가 원하는 class들로 분류할 수 있는 곳이기 때문
분류 방법은 softmax에서 나오는 확률 값에 따라서 판단하게 됨

(6) Feature Map

Feature들은 데이터에서 특징적인 정보들을 가지고 있음
Input단에 가까울수록 보다 세부적인 이미지 특성
반면, Output layer에 가까운 feature일 수록 전체적이고 고차원적인 특성을 가지게 됨
Input layer → Output layer로 갈 수록 표현하고자 하는 데이터의 특성 차원이 달라지게 되면서 각각이 다른 정보를 표현할 수 있게 됨
각각의 layer별로 가지고 있는 표현 특징을 'Feature Map'이라고 함

6. 본 코드에 관하여
(1) 문제 정의
본 이진 분류를 위하여 Kaggle의 데이터셋을 사용합니다. 이 셋은 약 25,000장의 개와 고양이 이미지를 포함하고 있으며 그 중 개인 CPU의 성능 문제로 약 500장 정도만 사용할 예정입니다. 여건이 더 되시는 분들은 데이터셋 전부를 사용하시면 더 정확한 성능의 딥러닝을 할 수 있을 것입니다. 
(2) 목표
Classificaiton을 이용하여 개와 고양이를 구분하는 적절한 알고리즘을 만들어서 이전에 보지 못한 이미지를 식별하는 것입니다.


(3) 케라스 소개

케라스는 거의 모든 종류의 딥러닝 모델을 간편하게 만들고 훈련시킬 수 있는 파이썬을 위한 딥러닝 프레임워크입니다.
케라스의 특징은 다음과 같습니다.
동일한 코드로 CPU와 GPU에서 실행 할 수 있습니다.
사용하기 쉬운 API를 가지고 있어 딥러닝 모델의 프로토타입을 빠르게 만들 수 있습니다.
(컴퓨터 비전을 위한) CNN, (시퀀스 처리를 위한) RNN을 지원하며 이 둘을 자유롭게 조합하여 사용할 수 있습니다.
다중 입력이나 다중 출력 모델, 층의 공유, 모델 공유 등 어떤 네트워크 구조도 만들 수 있습니다. 이 말은 GAN(Generative Adversarial Network) 부터 뉴럴 튜링 머신까지 케라스는 기본적으로 어떤 딥러닝 모델에도 적합하다는 뜻입니다.
한편, 케라스는 딥러닝 모델을 위한 고수준의 구성 요소를 제공하는데, 텐서 조작이나 미분 같은 저수준의 연산은 다루지 않습니다. 대신에 케라스의 백엔드 엔진 에서 제공하는 최적화된 텐서 라이브러리를 사용합니다. 케라스는 모듈 구조로 구성되어 있어 하나의 텐서 라이브러리에 국한하여 구현되어 있지 않고, 여러 가지 백엔드 엔진과 매끄럽게 연동됩니다. 현재는 TensorFlow, Theano, CNTK 3개를 백엔드 엔진으로 사용할 수 있습니다.

딥러닝 소프트웨어와 하드웨어 스택
TensorFlow, Theano, CNTK는 딥러닝을 위한 주요 플랫폼 중 하나입니다. 또한 케라스로 작성한 모든 코드는 아무런 변경 없이 이런 백엔드 중 하나를 선택해서 실행시킬 수 있습니다. 개발하는 중간에 하나의 백엔드가 특정 작업에 더 빠르다고 판단되면 언제든지 백엔드를 바꿀 수 있어 아주 유용합니다. 가정 널리 사용되고 확정성이 뛰어나는 텐서플로가 대부분의 딥러닝 작업에 기본으로 권장됩니다.


케라스를 이용해서 개발하기 (MNIST 데이터 이용)

케라스를 사용한 대부분의 작업 흐름은 다음과 같습니다.
입력 텐서와 타깃 텐서로 이루어진 훈련 데이터를 정의합니다.
입력과 타깃을 매핑하는 층으로 이루어진 네트워크(또는 모델)를 정의합니다.
손실 함수, 옵티마이저, 모니터링하기 위한 측정 지표를 선택하여 학습 과정을 설정합니다.
훈련 데이터에 대해 모델의 fit() 메서드를 반복적으로 호출합니다.
한편, 모델을 정의하는 방법은 두 가지인데, Sequential 클래스(가장 자주 사용하는 구조인 층을 순서대로 쌓아 올린 네트워크입니다.) 또는 함수형 API (완전히 임의의 구조를 만들 수 있는 비순환 유향 그래프(DAG)를 만듭니다.)를 사용합니다.
